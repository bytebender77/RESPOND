# ğŸš¨ RESPOND

**Multimodal Disaster Response Coordination System using Qdrant as Evolving Situational Memory**

*Convolve 4.0 | Qdrant MAS Track*

---

## ğŸ¯ What is RESPOND?

RESPOND transforms chaotic disaster reports into prioritized, actionable intelligence. During emergencies, reports flood in from social media, sensors, and calls. RESPOND ingests, understands, prioritizes, and evolvesâ€”helping responders save lives faster.

**Key Innovation:** Unlike static databases, RESPOND treats incidents as *evolving memories*â€”they update, reinforce, and decay over time without re-embedding vectors.

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ” **Hybrid Search** | Semantic + geo + temporal + status filters |
| ğŸ§  **Memory Evolution** | Incidents transition: pending â†’ acknowledged â†’ resolved |
| ğŸ“Š **Confidence Reinforcement** | Multi-source verification boosts confidence |
| â±ï¸ **Time Decay** | Fresh incidents automatically prioritized |
| ğŸ¯ **Action Recommendations** | Evidence-grounded operational decisions |
| ğŸ–¼ï¸ **Image & Audio** | Multimodal support (CLIP & Whisper) |

---

## ï¿½ Deliverables & Reproducibility

This project is designed to be **fully reproducible** and **end-to-end runnable**.

### ğŸ› ï¸ Prerequisites
- **Python 3.10+** installed
- **Qdrant** (Vector Database) - Running via Docker (Local) OR Cloud (Free Tier)
- **Git**

---

## ğŸš€ Installation & Setup

### Step 1: Clone the Repository

```bash
git clone https://github.com/bytebender77/RESPOND.git
cd RESPOND
```

### Step 2: Create Virtual Environment

A virtual environment keeps dependencies isolated from your system Python.

```bash
# Create virtual environment
python3 -m venv venv

# Activate it (macOS/Linux)
source venv/bin/activate

# Activate it (Windows)
# venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

This installs `fastapi`, `uvicorn`, `qdrant-client`, `sentence-transformers` (Text), `whisper` (Audio), and `CLIP` (Images).

### Step 4: Configure Environment Variables

Create a `.env` file in the root directory.

**Option A: Local Qdrant (Docker)**
If you have Docker installed, this is the easiest way.
```bash
docker run -p 6333:6333 qdrant/qdrant
```
Then your `.env` file can be:
```env
QDRANT_URL=http://localhost:6333
LOG_LEVEL=INFO
```

**Option B: Qdrant Cloud (Free Tier)**
1. Sign up at [cloud.qdrant.io](https://cloud.qdrant.io/).
2. Create a free cluster -> Get **URL** and **API Key**.
3. Update `.env`:
```env
QDRANT_URL=https://your-cluster-url.qdrant.io
QDRANT_API_KEY=your-api-key-here
```

---

## â–¶ï¸ Running the Application

### Step 1: Start the Backend API

```bash
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```
It will run at **http://localhost:8000**.
Visit **http://localhost:8000/docs** to explore the interactive API documentation.

### Step 2: Initialize Qdrant Collections

Open a **new terminal** (keep API running) and run:
```bash
curl http://localhost:8000/setup
```
*Expected output: `{"status":"ok","collections":{...}}`*

### Step 3: Start the Frontend Dashboard

You can simply open `frontend_basic/index.html` in your browser, or for a better experience:

```bash
cd frontend_basic
python3 -m http.server 3000
# or if you have 'serve' installed: npx serve
```
Visit **http://localhost:3000**.

---

## â˜ï¸ Deployment

We have specific guides for deploying to the cloud:
- **Backend**: Render (using `render.yaml`)
- **Frontend**: Vercel

ğŸ‘‰ **[Read the Deployment Guide](DEPLOYMENT_GUIDE.md)** for detailed cloud instructions.

---

## ğŸ® How to Test (Demo Flow)

1. **Quick Start**: Check the **[Demo Files Index](demo/DEMO_FILES_INDEX.md)** for comprehensive testing resources.
2. **Ingest Incident**:
   - Go to **Ingest** tab in the frontend.
   - Text: "Massive fire reported at Central Market, people trapped."
   - Click "Submit".
2. **Search**:
   - Go to **Search** tab.
   - Query: "fire near market".
   - You will see your incident.
3. **Reinforce (Audio)**:
   - Go to **Media** tab.
   - Use the Incident ID from step 1.
   - Upload an audio file (e.g., voice recording saying "The fire is spreading to the west wing").
   - Watch the confidence score increase!
4. **Action Recommendations**:
   - Go to **Actions** tab.
   - Get AI-driven recommendations based on the incidents.

---

## ğŸ“ Project Structure

```
respond/
â”œâ”€â”€ api/                    # FastAPI routes
â”œâ”€â”€ config/                 # Configuration & Settings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ embeddings/        # Text (MiniLM) & Image (CLIP) embedders
â”‚   â”œâ”€â”€ audio/             # Whisper transcriber
â”‚   â”œâ”€â”€ ingestion/         # Incident processing pipeline
â”‚   â”œâ”€â”€ memory/            # Evolution, decay, reinforcement logic
â”‚   â”œâ”€â”€ search/            # Hybrid search implementation
â”‚   â””â”€â”€ qdrant/            # Database client
â”œâ”€â”€ frontend_basic/        # Dashboard UI (HTML/CSS/JS)
â”œâ”€â”€ docs/                  # Technical documentation
â””â”€â”€ requirements.txt       # Dependencies
```

---

## ï¿½ Documentation Links
- **[Judge's Guide](JUDGE_GUIDE.md)** - Simplified run instructions.
- **[Technical Documentation](docs/TECHNICAL_DOCUMENTATION.md)** - Deep dive into architecture.
